import re
import torch
# 1. æ ¸å¿ƒæ­é…æå–ï¼ˆä¸å˜ï¼Œå¤„ç†å¸¦åŠ¨ä½œçš„queryï¼‰
# 1. æ ¸å¿ƒæ­é…æå–ï¼ˆä¸å˜ï¼Œå¤„ç†å¸¦åŠ¨ä½œçš„queryï¼‰
def extract_core_pair(query):
    food_actions = ["eat", "cook","cooking", "make", "bake", "fry", "prepare", "taste"]
    # 1. å…ˆæ¸…ç†ç‰¹æ®Šç¬¦å·ï¼ˆé—®å·ã€å°äºå·ç­‰ï¼‰
    query_clean = re.sub(r'[?.,!;<>â‰¤â‰¥]', '', query).strip().lower()
    # 2. è¿‡æ»¤â€œæ—¶é—´/çƒ­é‡â€ç­‰éé£Ÿç‰©æ¡ä»¶è¯ï¼ˆå…³é”®æ–°å¢ï¼‰
    condition_words = ["time", "min", "minute", "hour", "calorie", "kcal", "cal"]
    for word in condition_words:
        query_clean = re.sub(rf'\b{word}\b\s*[0-9]*', '', query_clean).strip()

    # 3. æå–â€œåŠ¨ä½œ+é£Ÿç‰©â€æ ¸å¿ƒæ­é…
    for action in food_actions:
        pattern = rf'\b{action}\b\s*(.*)'
        match = re.search(pattern, query_clean)
        if match:
            core_object = match.group(1).strip()
            stop_words = ["some", "the", "a", "an", "my", "your"]
            for stop in stop_words:
                core_object = re.sub(rf'\b{stop}\b', '', core_object).strip()
            if core_object:
                core_pair = f"{action} {core_object}"
                print(f"ğŸ¯ æå–æ ¸å¿ƒæ­é…ï¼š[{query}] â†’ [{core_pair}]")
                return core_pair
    return query_clean

# 2. å•å­—è¯è¡¥å…¨ï¼ˆä¸å˜ï¼‰
def complete_single_word_query(query):
    if len(query.strip().split()) == 1:
        completed_query = f"eat {query.strip()}"
        return completed_query
    if len(query.strip().split()) == 2:
        completed_query = f"how to make {query.strip()}"
        return completed_query
    return query

# 3. æœ€ç»ˆåˆ¤æ–­å‡½æ•°ï¼ˆæ–°å¢â€œçº¯é£Ÿç‰©åè¯â€è§„åˆ™ï¼‰
def is_food_query_final_solution(query, model, tokenizer):
    core_query = extract_core_pair(query)
    completed_query = complete_single_word_query(core_query)

    # å…³é”®æ–°å¢ï¼šè§„åˆ™åŒæ—¶åŒ…å«â€œåŠ¨ä½œ+é£Ÿæâ€å’Œâ€œçº¯é£Ÿç‰©åè¯ç»„åˆâ€
    judge_prompt = f"""
        ç”¨æˆ·ç±»å‹ï¼š é‚£äº›è®¨è®ºç¾é£Ÿç›¸å…³è¯é¢˜çš„ç”¨æˆ·
        è§„åˆ™ï¼š1. æ»¡è¶³ä»¥ä¸‹ä»»ä¸€æ¡ä»¶â†’YESï¼Œå¦åˆ™NOï¼Œä»…è¾“å‡ºYES/NOã€‚
             2. åˆ¤å®šç”¨æˆ·è¯é¢˜å¦‚æœæ˜¯ä¸é£Ÿç‰©ç›¸å…³çš„->YES, å¦åˆ™NO, ä»…è¾“å‡ºYES/NO
        1. å«eat/cook/cooking/make/bake/fry/about+é£Ÿæï¼ˆå¦‚make banana dessertâ†’YESï¼‰ï¼›
        2. çº¯é£Ÿç‰©åè¯ç»„åˆ.
        ç¤ºä¾‹1ï¼šeat appleâ†’YESï¼›ç¤ºä¾‹2ï¼šbanana dessertâ†’YESï¼›ç¤ºä¾‹3ï¼šuse phoneâ†’NOã€‚
        ç°åœ¨åˆ¤æ–­ï¼š{completed_query}â†’
        """

    with torch.no_grad():
        inputs = tokenizer.apply_chat_template(
            [
                {'role': "system", "content": 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åƒè´§ï¼Œåªéœ€åˆ¤è¯»è¿™æ®µå¯¹è¯æ˜¯ä¸æ˜¯åœ¨è®¨è®ºä¸ç¾é£Ÿç›¸å…³çš„è¯é¢˜'},
                {"role": "user", "content": judge_prompt},
            ],
            tokenize=True,
            add_generation_prompt=True,
            return_tensors="pt"
        ).to(model.device)

        outputs = model.generate(
            inputs,
            max_new_tokens=3,
            temperature=0.0,
            do_sample=False,
            pad_token_id=tokenizer.eos_token_id,
            attention_mask=torch.ones_like(inputs)
        )

    raw_output = tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True).strip()
    clean_output = re.sub(r'[ã€‚.\s]', '', raw_output).upper()
    print(f"ğŸ” æ ¸å¿ƒæ­é…åˆ¤æ–­ï¼š[{completed_query}] â†’ è¾“å‡ºï¼š[{raw_output}]")
    return clean_output